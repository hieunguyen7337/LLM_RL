{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOQJpc3ctHAHJyIH3TKn1cC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieunguyen7337/LLM_RL/blob/main/hangman_game_rl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (wandb on; bitsandbytes kept for big-model path)\n",
        "!pip -q install \"trl>=0.16.0\" transformers accelerate bitsandbytes peft wandb"
      ],
      "metadata": {
        "id": "sp27T7YMrbqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os, torch\n",
        "from datasets import Dataset, load_dataset\n",
        "from trl import GRPOTrainer, GRPOConfig\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "import re, ast\n",
        "from typing import List, Tuple"
      ],
      "metadata": {
        "id": "sC9vPDe10H19"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Toggle: use 4-bit for big models only\n",
        "model_name   = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
        "ENABLE_4BIT  = False      # <- small model: False. Set True for bigger models (e.g., â‰¥7B).\n",
        "GRAD_CKPT    = ENABLE_4BIT\n",
        "USE_CACHE    = not GRAD_CKPT  # avoid the \"caching incompatible with checkpointing\" spam\n",
        "DATA_PATH    = \"/content/LLM_RL/training_hangman_dataset.json\""
      ],
      "metadata": {
        "id": "0X2amOdu5yVY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ.setdefault(\"WANDB_PROJECT\", \"huggingface\")   # or \"grpo-demos\"\n",
        "os.environ.setdefault(\"WANDB_LOG_MODEL\", \"end\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XkFnTvh_52eN",
        "outputId": "b28835ea-e1c0-4c18-9eba-10804f46c90c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'end'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/hieunguyen7337/LLM_RL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpjFPXydr9Iu",
        "outputId": "0d27ff46-5831-4aad-f47c-c6f1bb045e6b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLM_RL'...\n",
            "remote: Enumerating objects: 86, done.\u001b[K\n",
            "remote: Counting objects: 100% (86/86), done.\u001b[K\n",
            "remote: Compressing objects: 100% (80/80), done.\u001b[K\n",
            "remote: Total 86 (delta 39), reused 13 (delta 5), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (86/86), 497.71 KiB | 1.05 MiB/s, done.\n",
            "Resolving deltas: 100% (39/39), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"json\", data_files=DATA_PATH)[\"train\"]"
      ],
      "metadata": {
        "id": "jl26_km5sE_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9qBER2uskRS",
        "outputId": "5d5d1f20-308d-41b5-9595-d10bdbb68e8e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['prompt', 'word'],\n",
              "    num_rows: 1825\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- helpers ---\n",
        "def _parse_prompt(prompt: str) -> Tuple[List[str], List[str]]:\n",
        "    \"\"\"Extract guessed letters (uppercased) and current state tokens ['_', 'A', ...].\"\"\"\n",
        "    guessed = []\n",
        "    m = re.search(r\"Guessed letters:\\s*(\\[[^\\]]*\\])\", prompt, flags=re.IGNORECASE | re.DOTALL)\n",
        "    if m:\n",
        "        try:\n",
        "            guessed = [s.upper() for s in ast.literal_eval(m.group(1)) if isinstance(s, str)]\n",
        "        except Exception:\n",
        "            guessed = []\n",
        "    guessed = list(dict.fromkeys(guessed))  # dedupe, keep order\n",
        "\n",
        "    state_tokens = []\n",
        "    m2 = re.search(r\"The current state is:\\s*([A-Za-z_ ]+)\", prompt, flags=re.IGNORECASE)\n",
        "    if m2:\n",
        "        state_tokens = [t.upper() for t in m2.group(1).split()]  # e.g. [\"_\", \"_\", \"P\", \"O\", \"_\", \"_\", \"E\", \"_\"]\n",
        "    return guessed, state_tokens"
      ],
      "metadata": {
        "id": "NG21lcevwHJp"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def _count_new_reveals(state_tokens: List[str], word_upper: str, guess: str) -> int:\n",
        "    \"\"\"How many new positions this guess would newly reveal given current visible state.\"\"\"\n",
        "    n = 0\n",
        "    L = len(word_upper)\n",
        "    for i in range(L):\n",
        "        st = state_tokens[i] if i < len(state_tokens) else \"_\"\n",
        "        if st == \"_\" and word_upper[i] == guess:\n",
        "            n += 1\n",
        "    return n"
      ],
      "metadata": {
        "id": "C4J628c3wKUQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reward funcs\n",
        "def hangman_reward_func(prompts, completions, word, **kwargs):\n",
        "    \"\"\"\n",
        "    Rewards in [-1, 1].\n",
        "      +0.8  correct new reveal (plus +0.2 per extra same-letter reveal)\n",
        "      +0.1  wrong letter\n",
        "      -0.5  already guessed\n",
        "      -1.0  no alphabetic output\n",
        "      -0.6  more than one alphabetic char generated\n",
        "    Tunables can be overridden via kwargs: pos_base, pos_multi_bonus, neg_wrong, neg_repeat, neg_missing, neg_multi_alpha.\n",
        "    \"\"\"\n",
        "    # tunables\n",
        "    pos_base        = float(kwargs.get(\"pos_base\", 0.8))\n",
        "    pos_multi_bonus = float(kwargs.get(\"pos_multi_bonus\", 0.2))\n",
        "    neg_wrong       = float(kwargs.get(\"neg_wrong\", 0.1))\n",
        "    neg_repeat      = float(kwargs.get(\"neg_repeat\", -0.5))\n",
        "    neg_missing     = float(kwargs.get(\"neg_missing\", -1.0))\n",
        "    neg_multi_alpha = float(kwargs.get(\"neg_multi_alpha\", -0.6))\n",
        "\n",
        "    rewards = []\n",
        "    for prompt, completion, w in zip(prompts, completions, word):\n",
        "        w_up = str(w).strip().upper()\n",
        "\n",
        "        guessed, state = _parse_prompt(str(prompt))\n",
        "\n",
        "        # default reward\n",
        "        r = 0.0\n",
        "\n",
        "        if not completion.isalpha():\n",
        "            rewards.append(neg_missing)\n",
        "            continue\n",
        "\n",
        "        if len(completion) == 0:\n",
        "            rewards.append(neg_missing)\n",
        "            continue\n",
        "\n",
        "        elif len(completion) != 1:\n",
        "            rewards.append(neg_multi_alpha)\n",
        "            continue\n",
        "\n",
        "        completion = completion.upper()\n",
        "\n",
        "        # logic\n",
        "        if completion in set(guessed):\n",
        "            r += neg_repeat\n",
        "        elif completion not in set(w_up):\n",
        "            r += neg_wrong\n",
        "        else:\n",
        "            new_reveals = _count_new_reveals(state, w_up, completion)\n",
        "            if new_reveals > 0:\n",
        "                r += pos_base + pos_multi_bonus * (new_reveals - 1)\n",
        "\n",
        "        # clamp to [-1, 1] for stability\n",
        "        r = max(-1.0, min(1.0, r))\n",
        "        rewards.append(float(r))\n",
        "    return rewards"
      ],
      "metadata": {
        "id": "oX54HkxzwBAf"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompts = [\"You are playing a game of Hangman.\\n\\nYour task is to guess a single character.\\n\\nThe word has a certain number of letters.\\nThe current state of the word is shown with guessed letters filled in and blanks for the unknown letters.\\nThe number of incorrect guesses remaining is listed.\\nAll letters that have been guessed so far are listed.\\n\\nYou will format your response as a single uppercase letter at the end\\n\\nThe word has 5 letters.\\nThe current state is: _ _ _ _ _\\nIncorrect guesses remaining: 4\\nGuessed letters: ['F', 'Q']\\n\\nCorrect response:\",\n",
        "           \"You are playing a game of Hangman.\\n\\nYour task is to guess a single character.\\n\\nThe word has a certain number of letters.\\nThe current state of the word is shown with guessed letters filled in and blanks for the unknown letters.\\nThe number of incorrect guesses remaining is listed.\\nAll letters that have been guessed so far are listed.\\n\\nYou will format your response as a single uppercase letter at the end\\n\\nThe word has 6 letters.\\nThe current state is: _ o _ _ _ _\\nIncorrect guesses remaining: 6\\nGuessed letters: ['O']\\n\\nCorrect response:\"]\n",
        "completions = [\"A\", \"o\"]\n",
        "words = [\"above\",\"policy\"]\n",
        "hangman_reward_func(prompts=prompts, completions=completions, word=words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rx4NZEWyw1Qw",
        "outputId": "4c5b2b2c-8872-4403-ffd1-382a07ba5593"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8, -0.5]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Tokenizer\n",
        "# ---------------------------\n",
        "tok = AutoTokenizer.from_pretrained(model_name, use_fast=True, padding_side=\"left\")\n",
        "if tok.pad_token is None:\n",
        "    tok.pad_token = tok.eos_token"
      ],
      "metadata": {
        "id": "7x1Fb30u6AiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Model (no quant for small; 4-bit kept for big)\n",
        "# ---------------------------\n",
        "quant = None\n",
        "if ENABLE_4BIT:\n",
        "    quant = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_quant_type=\"nf4\",\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_compute_dtype=torch.float16,\n",
        "    )\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"cuda:0\" if not ENABLE_4BIT else \"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    attn_implementation=\"sdpa\",\n",
        "    use_cache=USE_CACHE,\n",
        "    quantization_config=quant,\n",
        ")"
      ],
      "metadata": {
        "id": "kQfNxWal6Dv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# LoRA (kept for both; safe with/without quant)\n",
        "# ---------------------------\n",
        "peft_cfg = LoraConfig(\n",
        "    r=8, lora_alpha=16, lora_dropout=0.05, bias=\"none\",\n",
        "    task_type=\"CAUSAL_LM\",\n",
        "    target_modules=[\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"],\n",
        ")"
      ],
      "metadata": {
        "id": "Bb8c3qks6EhC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# GRPO config (W&B enabled; will save at epoch end)\n",
        "# ---------------------------\n",
        "args = GRPOConfig(\n",
        "    output_dir=\"qwen2.5-0.5b-Instruct-grpo\",\n",
        "    per_device_train_batch_size=16,  # keep divisible by num_generations\n",
        "    gradient_accumulation_steps=16,\n",
        "    num_generations=16,              # default is 8, batch must be divisible by this\n",
        "    max_prompt_length=512,          # default 512\n",
        "    max_completion_length=1,        # default 256, set\n",
        "    fp16=True,                      # T4 uses fp16\n",
        "    gradient_checkpointing=GRAD_CKPT,\n",
        "    report_to=\"wandb\",              # <-- keep W&B reporting\n",
        "    run_name=\"qwen2.5-0.5b-Instruct-GRPO-2\",  # change per run\n",
        "    logging_steps=3,\n",
        "    save_strategy=\"epoch\",          # save at epoch end too\n",
        "    save_total_limit=2,\n",
        ")"
      ],
      "metadata": {
        "id": "2lygjrwJ6GK4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = GRPOTrainer(\n",
        "    model=model,\n",
        "    reward_funcs=hangman_reward_func,\n",
        "    train_dataset=dataset,\n",
        "    args=args,\n",
        "    peft_config=peft_cfg, # LoRA reduces trainable params & VRAM\n",
        ")"
      ],
      "metadata": {
        "id": "dWN4YY2H6H8Q"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VJZ15VQ56Jhn",
        "outputId": "15288134-a27f-4969-87f8-719ea0536283"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Â·Â·Â·Â·Â·Â·Â·Â·Â·Â·\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhieunn16\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.21.1"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250825_125134-4ukchhd6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hieunn16/huggingface/runs/4ukchhd6' target=\"_blank\">qwen2.5-0.5b-Instruct-GRPO-2</a></strong> to <a href='https://wandb.ai/hieunn16/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hieunn16/huggingface' target=\"_blank\">https://wandb.ai/hieunn16/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hieunn16/huggingface/runs/4ukchhd6' target=\"_blank\">https://wandb.ai/hieunn16/huggingface/runs/4ukchhd6</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='342' max='342' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [342/342 1:16:07, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>63</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>66</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>69</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>78</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>81</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>84</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>87</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>93</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>99</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>102</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>108</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>111</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>114</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>117</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>123</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>126</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>129</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>132</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>138</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>141</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>147</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>153</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>156</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>159</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>162</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>165</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>171</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>174</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>177</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>180</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>183</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>186</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>189</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>195</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>198</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>201</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>204</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>207</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>210</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>213</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>219</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>222</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>228</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>231</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>234</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>237</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>243</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>246</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>249</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>252</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>255</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>258</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>261</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>267</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>270</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>273</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>276</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>279</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>282</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>285</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>291</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>294</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>297</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>303</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>306</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>309</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>315</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>318</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>321</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>324</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>327</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>330</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>333</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>339</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>342</td>\n",
              "      <td>-0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=342, training_loss=-2.5037463689059542e-08, metrics={'train_runtime': 4595.483, 'train_samples_per_second': 1.191, 'train_steps_per_second': 0.074, 'total_flos': 0.0, 'train_loss': -2.5037463689059542e-08})"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "save_dir = args.output_dir"
      ],
      "metadata": {
        "id": "JkC5ghPUCAMC"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------------------------\n",
        "# Save: adapter/weights + tokenizer + trainer state\n",
        "# ---------------------------\n",
        "trainer.save_model(save_dir)        # saves PEFT adapter (and weights) appropriately\n",
        "tok.save_pretrained(save_dir)\n",
        "trainer.save_state()"
      ],
      "metadata": {
        "id": "fIgKew6V6ZQF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# (Optional) If you're NOT using 4-bit, also export a merged FP16 model without LoRA adapters:\n",
        "if not ENABLE_4BIT:\n",
        "    try:\n",
        "        merged = trainer.model.merge_and_unload()\n",
        "        merged_dir = os.path.join(save_dir, \"merged-fp16\")\n",
        "        merged.save_pretrained(merged_dir)\n",
        "        tok.save_pretrained(merged_dir)\n",
        "        print(f\"Merged full model saved to: {merged_dir}\")\n",
        "    except Exception as e:\n",
        "        print(\"Merge skipped (not a PEFT model or unsupported):\", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4G0wn4WBhgu",
        "outputId": "7f1d38d8-e20d-401c-f142-1aeb48a12ded"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merged full model saved to: qwen2.5-0.5b-Instruct-grpo/merged-fp16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "\n",
        "# compress the folder\n",
        "shutil.make_archive(\"qwen2.5-0.5b-Instruct-grpo\", 'zip', \"qwen2.5-0.5b-Instruct-grpo\")\n",
        "\n",
        "# now download to your computer\n",
        "from google.colab import files\n",
        "files.download(\"qwen2.5-0.5b-Instruct-grpo.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "b4SKTQGTBi7h",
        "outputId": "53af4d89-24e8-41b7-b48a-8c5769ead826"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ab4cd8af-b988-41aa-91af-66650ead9118\", \"qwen2.5-0.5b-Instruct-grpo.zip\", 958526831)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}
