{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNi2Dj5aXkyVfLApW3hDOaF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hieunguyen7337/Qwen_LLM_RL/blob/main/Hangman_game_RL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "ougOkRqKW24P"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Qwen/Qwen3-0.6B\""
      ],
      "metadata": {
        "id": "jGgbsxOoW5GT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the tokenizer and the model\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\"\n",
        ")"
      ],
      "metadata": {
        "id": "yQehCjHWW6vE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Os7VIYJIWkEx",
        "outputId": "8c8c4a93-78bb-41fc-b921-29c0e7a9c430"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thinking content: <think>\n",
            "Okay, let's see. I need to figure out the correct letter to guess in this Hangman game. The word has 6 letters, and the current state is that there are four underscores, and the remaining guesses are 6. The guessed letters are empty. So the goal is to determine which letter to guess next.\n",
            "\n",
            "Wait, but the problem says \"output a single letter at the end\". Hmm, maybe I need to pick a letter that's not guessed yet, not in the wrong position, and not part of the wrong letters. Let me think.\n",
            "\n",
            "The initial state shows that there are four underscores. So the word has 6 letters, and the underscores are the letters that haven't been guessed yet. So the possible letters to guess could be any of the 6 letters that haven't been guessed yet, but also not in the wrong positions. Wait, but the problem says that the current state is \"_ _ _ _ _ _\", so maybe the underscores are the letters that need to be filled in. The remaining guesses are 6. So the user has 6 guesses left, but the word is 6 letters long. So the user is allowed to guess any of the 6 letters, but they have to choose one that hasn't been guessed yet and not in the wrong positions.\n",
            "\n",
            "Wait, but the problem says to output a single letter. So perhaps the answer is any of the letters that haven't been guessed yet. But since the guessed letters are empty, maybe any of the letters. But maybe there's a specific answer expected here. Wait, maybe the problem is a simple one where the user guesses any letter. Let me check again.\n",
            "\n",
            "The task is to guess one letter. Output a single letter. So perhaps the correct answer is any of the letters. But how to choose? Maybe the problem expects me to pick a random letter. Wait, but maybe there's a specific answer. Wait, maybe I'm overcomplicating. Let me think again.\n",
            "\n",
            "The word has 6 letters. The current state is underscores, so the letters to guess are those that are not yet guessed. The remaining guesses are 6. So the user has 6 guesses left. So they can choose any of the 6 letters, but they need to pick one. Since there's no information about the actual letters, maybe the answer is any of the letters. But how to choose? Maybe the problem expects me to pick a random one. For example, maybe the answer is 'e', but that's just a guess.\n",
            "\n",
            "Wait, but perhaps the problem is a test. Maybe the actual letters are something else. Wait, maybe there's a typo here. Let me check again. The initial state is underscores. The remaining guesses are 6. So the user can guess any of the letters. But since the problem says \"output a single letter\", maybe the answer is one of the letters. But without more information, how to choose?\n",
            "\n",
            "Wait, maybe the problem is designed such that the correct answer is any letter. For example, the user can choose any letter. So perhaps the answer is 'e'. But maybe there's a specific answer expected. Alternatively, maybe the problem is a trick question where the answer is none, but that doesn't make sense. Alternatively, maybe the answer is 'e' because it's the most common letter. Or maybe the problem is designed to have a specific answer, but without more context, it's hard to tell. \n",
            "\n",
            "Wait, maybe I'm missing something. The problem says the current state is \"_ _ _ _ _ _\", which implies that the underscores are the letters that need to be filled. The user has 6 guesses left. So the user can choose any of the 6 letters. But the problem says to output a single letter. So perhaps the answer is any letter. But how to choose? Maybe the problem expects me to pick the first letter, which is 'a', but that's a guess. \n",
            "\n",
            "Alternatively, maybe the problem is a simple one where the correct answer is 'e', as a common letter. But since the problem doesn't provide the actual letters, perhaps the answer is 'e'. \n",
            "\n",
            "Wait, maybe I should think of it as a game where the user can choose any letter, so the answer is any of the letters. But since the user hasn't been given the actual letters, perhaps the answer is 'e' as a placeholder. \n",
            "\n",
            "Alternatively, perhaps the problem is designed such that the answer is 'e', but I'm not sure. \n",
            "\n",
            "Wait, maybe I'm overcomplicating. The problem says that the user has 6 guesses left, and the current state is underscores. So the user can choose any letter. Since there's no specific instruction to choose, perhaps the answer is any letter. But the problem says to output a single letter. Maybe the answer is 'e'. \n",
            "\n",
            "But maybe there's a standard answer. For example, in some cases, the answer is 'e'. Alternatively, maybe the problem is expecting me to pick the first letter, which is 'a'. But without more information, it's impossible to know. \n",
            "\n",
            "Hmm, perhaps I need to make a best guess. Let's think again. The word has 6 letters, and the underscores are the letters that need to be guessed. The user has 6 guesses left. So they can choose any of the 6 letters. But since the problem says to output a single letter, perhaps the answer is 'e'. \n",
            "\n",
            "Alternatively, maybe the problem expects me to pick a letter that's not guessed yet. But since the guessed letters are empty, any letter would work. \n",
            "\n",
            "But since the problem says to output a single letter, perhaps the answer is 'e'. \n",
            "\n",
            "Alternatively, maybe the answer is 'a'. \n",
            "\n",
            "Wait, perhaps I should just pick a random letter. Let me think of possible letters. Since there are 6 letters, maybe the answer is 'e'. \n",
            "\n",
            "But maybe the problem is a trick. For example, the word is \"ELEPHANT\", but that's 7 letters. No, the word has 6 letters. Maybe it's \"ELEPHANT\" but that's 7. \n",
            "\n",
            "Alternatively, maybe the word is \"ELEPHANT\" but that's 7 letters. \n",
            "\n",
            "Alternatively, maybe the word is \"LEMON\". But that's 4 letters. \n",
            "\n",
            "Wait, maybe the problem is a simple one where the answer is any letter. So perhaps the answer is 'e'. \n",
            "\n",
            "But I'm not sure. Alternatively, maybe the answer is 'a'. \n",
            "\n",
            "Alternatively, perhaps the problem is a test where the answer is 'e'. \n",
            "\n",
            "Given that, I think the answer is 'e'. So the output is 'e'.\n",
            "</think>\n",
            "content: The game requires guessing one letter to complete the Hangman. Since the word has 6 letters and the current state shows underscores, the correct letter must be any of the 6 letters that haven't been guessed yet. However, without specific information about the word, the most logical and common choice (based on typical game scenarios) is to guess the letter **'e'**.\n",
            "\n",
            "Final Answer: **e**\n"
          ]
        }
      ],
      "source": [
        "# prepare the model input\n",
        "prompt = \"\"\"You are playing a game of Hangman.\n",
        "\n",
        "The word has 6 letters.\n",
        "The current state is: _ _ _ _ _ _\n",
        "Incorrect guesses remaining: 6\n",
        "Guessed letters: [ ]\n",
        "\n",
        "Your task is to guess one letter. Output a single letter at the end.\"\"\"\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# conduct text completion\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=32768\n",
        ")\n",
        "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
        "\n",
        "# parsing thinking content\n",
        "try:\n",
        "    # rindex finding 151668 (</think>)\n",
        "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
        "except ValueError:\n",
        "    index = 0\n",
        "\n",
        "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
        "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
        "\n",
        "print(\"thinking content:\", thinking_content)\n",
        "print(\"content:\", content)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the model input\n",
        "prompt = \"\"\"You are playing a game of Hangman.\n",
        "\n",
        "The word has 6 letters.\n",
        "The current state is: P _ _ _ O _\n",
        "Incorrect guesses remaining: 5\n",
        "Guessed letters: [E, P, O]\n",
        "\n",
        "Your task is to either guess one character or guess the full word.\n",
        "Format your response as follows:\n",
        "- To guess a character, output a single letter preceded by \"CHARACTER:\"  at the end (e.g., \"A\").\n",
        "- To guess the full word, output the word preceded by \"WORD:\" at the end (e.g., \"WORD: PYTHON\").\n",
        "\n",
        "Your guess:\"\"\"\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "text = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize=False,\n",
        "    add_generation_prompt=True,\n",
        "    enable_thinking=True # Switches between thinking and non-thinking modes. Default is True.\n",
        ")\n",
        "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "# conduct text completion\n",
        "generated_ids = model.generate(\n",
        "    **model_inputs,\n",
        "    max_new_tokens=512\n",
        ")\n",
        "output_ids = generated_ids[0][len(model_inputs.input_ids[0]):].tolist()\n",
        "\n",
        "# parsing thinking content\n",
        "try:\n",
        "    # rindex finding 151668 (</think>)\n",
        "    index = len(output_ids) - output_ids[::-1].index(151668)\n",
        "except ValueError:\n",
        "    index = 0\n",
        "\n",
        "thinking_content = tokenizer.decode(output_ids[:index], skip_special_tokens=True).strip(\"\\n\")\n",
        "content = tokenizer.decode(output_ids[index:], skip_special_tokens=True).strip(\"\\n\")\n",
        "\n",
        "print(\"thinking content:\", thinking_content)\n",
        "print(\"content:\", content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wA7ExoHRdVW6",
        "outputId": "11da40b4-7851-4acc-dafd-a28250f35689"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thinking content: \n",
            "content: <think>\n",
            "Okay, let's see. I need to figure out the answer to this Hangman game. The user has provided the current state, the number of incorrect guesses left, and the letters that have been guessed. The word is 6 letters long, and the current state is P _ _ _ O _. So far, the letters guessed are E, P, O. The remaining letters in the word are probably A, N, T, H, and maybe another one? Wait, the current state has P, then underscores, then O. So the letters in the word are P, A, N, T, H, and O? Wait, no, the original word is 6 letters. Let me think again. The current state is P _ _ _ O _. So the letters guessed are P, O. The current state shows that the word has P, then three underscores, then O. So the letters not guessed yet are A, N, T. Because the word is 6 letters. So the word is P A N T H O? Or maybe P A N T O H? Wait, the current state shows O at the end. So the word is 6 letters. Let me count: P, then three underscores, then O. So the word is P followed by three letters, then O. So the full word would be P A N T H O? Or P A N T O H? Wait, but the underscores are three letters. So the letters not guessed yet are A, N, T. So the full word is P A N T H O. But the user's current state shows O at the end, so the word is P followed by A, N, T, H, O. So the letters are P, A, N, T, H, O. That makes 6 letters. So the word is PYTHON. Wait, but the underscores are three letters. Let me check again. The initial state is P _ _ _ O _. So the underscores are three letters. So the letters are P, A, N, T, H, O. So the full word is PYTHON. But let me confirm: P is first, then A, then N, then T, then H, then O. So yes, the word is PYTHON. So the user's task is to guess the full word, so output WORD: PYTHON. But wait, the user's current state shows that O is already guessed. So in the current state, the letters guessed are E\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRGhkebBeuQ3",
        "outputId": "511e8ca3-fa23-42d0-c556-0d8ce0dd0b98"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[151644,    872,    198,   2610,    525,   5619,    264,   1809,    315,\n",
              "          40775,   1515,    382,    785,   3409,    702,    220,     21,  11931,\n",
              "            624,    785,   1482,   1584,    374,     25,    393,    716,    716,\n",
              "            716,    506,  22983,  40468,  60537,   9664,     25,    220,     20,\n",
              "            198,  16780,  21712,  11931,     25,    508,     36,     11,    393,\n",
              "             11,    506,   2533,   7771,   3383,    374,    311,   2987,   7942,\n",
              "            825,   3668,    476,   7942,    279,   2480,   3409,    624,   4061,\n",
              "            697,   2033,    438,  11017,    510,     12,   2014,   7942,    264,\n",
              "           3668,     11,   2550,    264,   3175,   6524,  52480,    553,    330,\n",
              "          15237,  37397,   2974,    220,    518,    279,    835,    320,     68,\n",
              "           1302,   2572,    330,     32,  38609,     12,   2014,   7942,    279,\n",
              "           2480,   3409,     11,   2550,    279,   3409,  52480,    553,    330,\n",
              "           7227,   2974,    518,    279,    835,    320,     68,   1302,   2572,\n",
              "            330,   7227,     25,  76678,  80984,   7771,   7942,     25, 151645,\n",
              "            198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}